---
title: "Final Data Analysis Project"
date:  "Write up due April 28 at 5 pm"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


For this project you will take the role of a consultant hired by a real estate investment firm in Ames, Iowa, a mid-west town in the United States, to analyze data in order to help provide insight into how the firm should invest for highest profits, and to quantify and communicate to the company management what types of real estate properties are good investments and why. They have provided you with data on housing sales from between 2006 to 2010 that contains information about the characteristics of the house (number of bedrooms, number of bathrooms, square footage, etc.) and the house's sale price. The codebook for this data set is [available online here ](https://ww2.amstat.org/publications/jse/v19n3/decock/datadocumentation.txt)  or in the Data folder in your repo.

## About the Data Analysis Project

It's generally a bad idea to buy the most expensive house in the neighborhood. And remember the real estate agents' mantra: Location, location, location! Keep in mind that the goal is to make money for your investors, and hence investing in a property that is overvalued (costing more than it is worth) is rarely a good idea. This means that it's critical to know which properties are overvalued and which are undervalued.  The company that hired you has many questions for you about the housing market. It is up to you to decide what methods you want to use (frequentist or Bayesian) to answer these questions, and implement them to help to identify undervalued and overvalued properties.


You will have three data sets: a subset for training, a subset for testing, and a third subset for validation. You will be asked to do data exploration and build your model (or models) initially using only the training data. Then, you will test your model on the testing data, and finally validate using the validation data. We are challenging you to keep your analysis experience realistic, and in a realistic scenario you would not have access to all three of these data sets at once.  You will be able to see on our scoreboard how well your team is doing based on its predictive performance on the testing data.  After your project is turned in you will see the final score on the validation set.

All members of the team should contribute equally and answer any questions about the analysis at the final presentation.

For your analysis create a new notebook named "project.Rmd"
and update accordingly rather than editing this.


### Read in Training Data

To get started read in the training data. 
```{r read-data}
library(dplyr)
library(tidyr)
load("ames_train.Rdata")

print(paste0("The dataset has ", dim(ames_train)[1], " number of observations and ", dim(ames_train)[2], " features"))

#Variables with NA's and their proportion of missing data
miss = apply(is.na(ames_train), 2, sum)
miss_prop = round(miss[miss>0]/nrow(ames_train), 3)
print(miss_prop) 
which(miss_prop>0.5) # four features have greater than 50% of data "missing" -- drop these variables
```


Notes about data cleaning:

We dropped “utilities” (type of utilities available) since in the training set, only 2 observations did not have all the utilities (electricity, gas, water and sewage). Intuitively, most modern property are equipped with these basic public utilities and keeping the variable would therefore be unnecessary. 

We also dropped “condition 2” (proximity to various conditions if more than one is present) since it seemed redundant from our training set. Given Condition 1, only 12 properties were not close to normal conditions. 

In the original scale, 1990 and 1900 would not be much different. Therefore, we changed the scale to the number of years since last construction or remodelling, subtracted from year 2010 (the end year in the dataset). 

Another variable dropped in our model was “roof material” since only 1% of the property used material other than “standard composite shingle”. Similarly, “heating” was also dropped since more than 95% of the property has gas forced warm air furnace (GasA) instead of other types of heating.

For “exterior quality” and “exterior condition”	, we recoded these ordinal variables to 1-5 to replace the original scale of conditions (from poor to excellent). Similarly, we recoded “basement exposure” and “basement rating” except that the new scale would start from 0 for properties without basement. 
												
Exter Qual (Ordinal): Evaluates the quality of the material on the exterior


						
      Ex       Excellent
       Gd       Good
       TA       Average/Typical
       Fa       Fair
       Po       Poor


						
Exter Cond (Ordinal): Evaluates the present condition of the material on the exterior


						
      Ex       Excellent
       Gd       Good
       TA       Average/Typical
       Fa       Fair
       Po       Poor


Continuous variables such as “1st floor square feet” and “2nd floor square feet” were log-transformed for interpretation purpose. 

For variable “functional”, we recoded different ordinal levels into binary levels --- typical functionality or not, including minor and major deductions.  		

We summed up the number of bathrooms to one continuous variable. Note that one half-bathroom would be coded as 0.5.	
```{r}
#Consider removing Lot.Frontage if not important
ames_train[is.na("Alley"),"Alley"] <- "None"
#Heating quality as ordinal
#Change Electrical to integer
#Change Kitchen Quality to integer
#Consider putting Year.Built in age terms
#Make Fireplace quality an integer
#Make Fences an integer
#Integers for all basement, garage, and pool variables
recode_factor(ames_train$Exter.Qual, `Po` = "1", `Fa` = "2", `TA` = "3", `Gd` = "4", `Ex` = "5") 
recode_factor(ames_train$Exter.Cond, `Po` = "1", `Fa` = "2", `TA` = "3", `Gd` = "4", `Ex` = "5") 
recode_factor(ames_train$Bsmt.Qual, `NoBasement` = "NA", `Po` = "1", `Fa` = "2", `TA` = "3", `Gd` = "4", `Ex` = "5") 
recode_factor(ames_train$Bsmt.Cond, `NoBasement` = "NA", `Po` = "1", `Fa` = "2", `TA` = "3", `Gd` = "4", `Ex` = "5") 
recode_factor(ames_train$Bsmt.Exposure, `NoBasement` = "NA", `NoExposure` = "0", `Mn` = "1", `Av` = "2", `Gd` = "3") 
                          
var_drop = c("Alley", "MS.SubClass", "Bsmt.Full.Bath", "Bsmt.Half.Bath", "Full.Bath", "Half.Bath", "Misc.Feature", "Pool.QC", "Fence")
train = ames_train %>%   filter(!is.na(Bsmt.Full.Bath)) %>%
                        filter(!is.na(Bsmt.Half.Bath)) %>%
                        mutate(Baths = Bsmt.Full.Bath + 0.5*Bsmt.Half.Bath + Full.Bath + 0.5*Half.Bath) %>%
                        mutate(Typical.Functionality = ifelse(Functional == "Typ", 1, 0)) %>%
                        mutate(ms.subclass = factor(MS.SubClass)) %>%
                        filter(!is.na(Lot.Frontage)) %>%
                        filter(!is.na(Mas.Vnr.Area)) 
train = train[ , !names(train) %in% var_drop]
# #Finds variables with only one unique observation
# for(p in 1:length(train)) {
#   entries = unique(train[,p])
#   if (nrow(entries) == 1) print(entries)
# }
```

The `Neighborhood` variable, typically of little interest other than to model the location effect, may be of more relevance when used with the [map](http://www.amstat.org/publications/jse/v19n3/decock/AmesResidential.pdf).

We are restricting attention to just the "normal sales" condition.


## Part I: Simple Model

In the first model you are allowed only limited manipulations of the original data set to predict the sales price `price`. You are allowed to take power transformations of the original variables [square roots, logs, inverses, squares, etc.] but you are NOT allowed to create interaction variables. This means that a variable may only be used once in an equation [if you use $ x^2$ don’t use $x$]. Additionally, you may eliminate any data points you deem unfit. This model should have a minimum r-square of 73% (in the original units) and contain at least 6 variables but fewer than 20.   


```{r}
library(MASS)
model=lm(price~., data=train)
boxcox(model)

model=lm(log(price)~., data=train)
summary(model)
```


```{r model1}
model=lm(log(price)~ms.subclass + MS.Zoning + log(Lot.Frontage) + log(area) + Street + Alley + Lot.Shape + Land.Contour + Lot.Config + Land.Slope + Neighborhood + Condition.1 + Bldg.Type + House.Style + Overall.Qual + Overall.Cond + Year.Built + Year.Remod.Add + Roof.Style + Exterior.1st + Exterior.2nd + Mas.Vnr.Type + log(Mas.Vnr.Area + 1) + Exter.Qual + Exter.Cond + Foundation + Bsmt.Qual + Bsmt.Cond + Bsmt.Exposure + Heating.QC + Central.Air + Electrical + log(X1st.Flr.SF) + log(X2nd.Flr.SF) + Baths + Bedroom.AbvGr + Kitchen.AbvGr + TotRms.AbvGrd + Paved.Drive + log(Wood.Deck.SF + 1) + log(Open.Porch.SF + 1) + log(Enclosed.Porch + 1) + log(X3Ssn.Porch + 1) + log(Screen.Porch + 1) + log(Misc.Val + 1) + Mo.Sold + Yr.Sold + Sale.Type + log(TotalSq), data=train)
summary(model)

#Model Selection by AIC
step(model, k=2)
AIC_model = lm(formula = log(price) ~ PID + area + MS.SubClass + MS.Zoning + 
    Lot.Area + Lot.Shape + Utilities + Land.Slope + Neighborhood + 
    Condition.1 + Bldg.Type + House.Style + Overall.Qual + Overall.Cond + 
    Year.Built + Year.Remod.Add + Roof.Style + Roof.Matl + Exterior.1st + 
    Exterior.2nd + Exter.Qual + Exter.Cond + Foundation + BsmtFin.SF.1 + 
    BsmtFin.SF.2 + Bsmt.Unf.SF + Heating + Heating.QC + Central.Air + 
    Electrical + X1st.Flr.SF + X2nd.Flr.SF + Bsmt.Full.Bath + 
    Kitchen.Qual + Functional + Garage.Cars + Garage.Area + Paved.Drive + 
    Wood.Deck.SF + Open.Porch.SF + Enclosed.Porch + Screen.Porch + 
    Mo.Sold + Yr.Sold + has.fence + has.fireplace, data = train)
summary(AIC_model)

#Model Selection by BIC
step(model, k=log(nrow(train)))
BIC_model = lm(formula = log(price) ~ PID + area + MS.Zoning + Lot.Area + 
    Neighborhood + Condition.1 + Bldg.Type + Overall.Qual + Overall.Cond + 
    Year.Built + Year.Remod.Add + BsmtFin.SF.1 + BsmtFin.SF.2 + 
    Bsmt.Unf.SF + Central.Air + Bsmt.Full.Bath + Kitchen.Qual + 
    Functional + Garage.Cars + Garage.Area + Open.Porch.SF + 
    Enclosed.Porch + Screen.Porch + has.fireplace, data = train)
summary(BIC_model)

#Use Boosting to find important variables

library(gbm)

boost = gbm(log(price) ~ PID + area + MS.Zoning + Lot.Area + 
    Neighborhood + Condition.1 + Bldg.Type + Overall.Qual + Overall.Cond + 
    Year.Built + Year.Remod.Add + BsmtFin.SF.1 + BsmtFin.SF.2 + 
    Bsmt.Unf.SF + Central.Air + Bsmt.Full.Bath + Kitchen.Qual + 
    Functional + Garage.Cars + Garage.Area + Open.Porch.SF + 
    Enclosed.Porch + Screen.Porch + has.fireplace, data = train, distribution="gaussian", n.trees=5000, interaction.depth = 1, shrinkage=0.01, verbose = F)

summary(boost)

#Sparse Model (removed variables to bring the number below 20)
sparse_model = lm(log(price) ~ area + MS.Zoning + Lot.Area + 
    Neighborhood + Condition.1 + Overall.Qual + Overall.Cond + 
    Year.Built + Year.Remod.Add + BsmtFin.SF.1 + BsmtFin.SF.2 + 
    Bsmt.Unf.SF + Central.Air + Bsmt.Full.Bath + Kitchen.Qual + 
    Functional + Garage.Cars + Garage.Area + has.fireplace, data = train)
summary(sparse_model)
plot(sparse_model)
termplot(sparse_model, 
    data = train)

#Trying to detect non-linearity
attach(train)
plot(log(area), log(price))
plot(log(Lot.Area), log(price))
plot(log(Overall.Qual), log(price))
plot(log(Overall.Cond), log(price))
plot(log(Year.Built), log(price))
plot(log(Year.Remod.Add, log(price)))
plot(BsmtFin.SF.1, log(price))
plot(BsmtFin.SF.2, log(price))
plot(Bsmt.Unf.SF, log(price))
plot(Bsmt.Full.Bath, log(price))
plot(Garage.Cars, log(price))
plot(Garage.Area, log(price))

#Simple model (final)
#Removed Kitchen.Qual because the test set has one more level for that variable and it won't run because of that; we may try finding another way to deal with this though, as all its levels on this model are highly significant, though it doesn't affect the R-squared that much
model1 = lm(log(price) ~ log(area) + MS.Zoning + log(Lot.Area) + 
    Neighborhood + Condition.1 + log(Overall.Qual) + log(Overall.Cond) + 
    log(Year.Built) + log(Year.Remod.Add) + BsmtFin.SF.1 + BsmtFin.SF.2 + 
    Bsmt.Unf.SF + Central.Air + Bsmt.Full.Bath +
    Functional + Garage.Cars + Garage.Area + has.fireplace, data = train[-c(168, 461, 787),])
summary(model1)
plot(model1)

#Plot Price Ranges of each neighborhood
library(ggplot2)

neighborhood.price.range = ggplot(train, aes(x = log(price), y = reorder(Neighborhood, desc(log(price)), median))) +
  geom_polygon(color="SlateGray",size = 1, alpha=1) + theme_light() + coord_flip() + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + labs(y="Neighborhood")

plot(neighborhood.price.range)
```



### Model Evaluation on Test Data
Create predicted values for price using your model using the testing data

```{r read-test-data}
load("ames_test.Rdata")

#Variables with NA's and their proportion of missing data
miss = apply(is.na(ames_train), 2, sum)
miss_prop = round(miss[miss>0]/nrow(ames_train), 3)
print(miss_prop) 
which(miss_prop>0.5) # four features have greater than 50% of data missing


#Created binary variables for whether or not a house as an alley, pool, fence, misc. feature, fireplace, basement or garage, as I thought it may be more meaningful- Tom
#May consider adding Lot.Frontage back in, as it only had 286 missing
#Have to decide between filtering out N/A's for different Garage variables and only including 'has.garage'
#Have to decide between filtering out N/A's for different Basement variables and only including 'has.basement'
test = ames_test %>%  mutate(has.alley = ifelse(!is.na(Alley), 1, 0)) %>%
                        mutate(has.pool = ifelse(Pool.Area > 0, 1, 0)) %>%
                        mutate(has.fence = ifelse(!is.na(Fence), 1, 0)) %>%
                        mutate(has.shed.or.second.garage = ifelse(!is.na(Misc.Feature), 1, 0)) %>%
                        mutate(has.fireplace = ifelse(Fireplaces > 0, 1, 0)) %>%
                        mutate(has.basement = ifelse(!is.na(Bsmt.Qual), 1, 0)) %>%
                        mutate(has.garage = ifelse(!is.na(Garage.Type), 1, 0))
                  
```

```{r predict-model1, echo=FALSE}
Yhat = predict(model1, newdata=test, interval="prediction")
```

You should save your predictions in a dataframe with columns for `PID`  (property identifier), `fit`, predicted values on the test data, and where possible `lwr` and `upr`, lower and upper 95% interval estimates for predicting `price`. 

```{r create }
Y = test$price
Yhat = exp(Yhat)

#Bias
mean(Yhat[,1] - Y)

#Maximum Deviation
max(abs(Y - Yhat[,1]))

#Mean Absolute Deviation
mean(abs(Y - Yhat[,1]))

#RMSE
sqrt(mean((Y - Yhat[,1])^2))

#Coverage
mean(Yhat[,"lwr"] < Y & Yhat[,"upr"] > Y)

# name dataframe as predictions! DO NOT CHANGE
predictions = as.data.frame(Yhat)
predictions$PID = test$PID
save(predictions, file="predict.Rdata")
```

Your models will be evaluated on the following criteria on the test data: 

* Bias:  Average (Yhat-Y)  positive values indicate the model tends to overestimate price (on average) while negative values indicate the model tends to underestimate price.

* Maximum Deviation:  Max |Y-Yhat| -  identifies the worst prediction  made in the validation data set.

* Mean Absolute Deviation:  Average |Y-Yhat| - the average error (regardless of sign).

* Root Mean Square Error: Sqrt Average (Y-Yhat)^2

* Coverage:  Average( lwr < Y < upr) 

In order to have a passing wercker badge, your file for predictions needs to be the same length as the test data, with three columns:  fitted values, lower CI and upper CI values in that order with names, fit, lwr, and upr respectively.

You will be able to see your scores on the score board (coming soon!).  They will be initialized by a predction based on the mean in the training data.

_Model Check_ - Test your prediction on the first observation in the training and test data set to make sure that the model gives a reasonable answer and include this in a supplement of your report. This should be done BY HAND using a calculator (this means use the raw data from the original dataset and manually calculate all transformations and interactions with your calculator)! Models that do not give reasonable answers will be given a minimum 2 letter grade reduction. Also be careful as you cannot use certain transformations [log or inverse x] if a variable has values of 0.




### Part II: Complex Model

In this part you may go all out for constructing a best fitting model for predicting housing prices using methods that we have covered this semester.  You should feel free to to create any new variables (such as quadratic, interaction, or indicator variables, splines, etc). The variable `TotalSq = X1st.Flr.SF+X2nd.Flr.SF` was added to the dataframe (that does not include basement area, so you may improve on this. A relative grade is assigned by comparing your fit on the test set to that of your fellow students with bonus points awarded to those who substantially exceed their fellow students and point reductions occurring for models which fit exceedingly poorly.  

Update your predictions using your complex model to provide point estimates and CI.

```{r predict-model2, echo=FALSE}
# replace model1 with model2
predictions = as.data.frame(predict(model1, newdata=ames_test, interval = "pred"))
predictions$PID = ames_test$PID
save(predictions, file="predict.Rdata")
```

You may iterate here as much as you like exploring different models until you are satisfied with your results.




### Part III: Write Up

Once you are satisfied with your model, provide a write up of your data analysis project in a new Rmd file/pdf file: `writeup.Rmd` by copying over salient parts of your R notebook. The written assignment consists of five parts:

1. Exploratory data analysis (20 points): must include three correctly labeled graphs and an explanation that highlight the most important features that went into your model building.


2. Development and assessment of an initial model from Part I (10 points)

* Initial model: must include a summary table and an explanation/discussion for variable selection.  Interpretation of coefficients desirable for full points.

* Model selection: must include a discussion

* Residual: must include a residual plot and a discussion

* RMSE: must include an RMSE and an explanation  (other criteria desirable)

* Model testing: must include an explanation



3. Development of the final model (20 points)

* Final model: must include a summary table

* Variables: must include an explanation

* Variable selection/shrinkage: must use appropriate method and include an explanation



4. Assessment of the final model (25 points)

* Residual: must include a residual plot and a discussion

* RMSE: must include an RMSE and an explanation  (other criteria desirable)

* Model evaluation: must include an evaluation discussion

* Model testing : must include a discussion

* Model result: must include a selection of the top 10 undervalued and overvalued houses



5. Conclusion (10 points): must include a summary of results and a discussion of things learned



### Part IV
Create predictions for the validation data from your final model and write out to a file `prediction-validation.Rdata`
This should have the same format as the models in Part I and II.

10 points



### Class Presentations

Each Group should prepare 5 slides in their Github repo:  (save as slides.pdf)

* Most interesting graphic  (a picture is worth a thousand words prize!)  

* Best Model (motivation, how you found it, why you think it is best)

* Best Insights into predicting Sales Price.

* 2 Best Houses to purchase  (and why)

* Best Team Name/Graphic

We will select winners based on the above criteria and overall performance.


Finally your repo should have: `writeup.Rmd`, `writeup.pdf`, `slides.Rmd` (and whatever output you use for the presentation) and `predict.Rdata` and `predict-validation.Rdata`.
